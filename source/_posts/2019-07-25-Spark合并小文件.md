---
title: Spark Streaming合并小文件
date: 2019-07-25 15:36:44
categories:
- Technology
tags:
- Spark
- Spark Streaming
---

## 1.问题背景
使用streaming每五秒钟往HDFS写文件，会在HDFS上这个表的目录下生成很多的小文件（每次批处理一个partition一个文件），这个时候如果想在HIVE中进行统计,计算的时候,会产生很多个Map,严重影响计算的速度

## 2.解决方案
### 2.1 纯写SQL方案
- 实现说明
```sql
## 静态分区方式
insert overwrite table ods_login_log partition(dt=2019070118) select uid,user_name,game_id,login_time,server_id,agent_id,site_id,cplaceid,adid,turn,login_agent_id,login_site_id,reg_game_time,reg_time,imei,model,devicebrand,systemversion,mnos,ip,sdk_version_code,app_version_code,data_plat from ods_login_log where dt=2019070118;

## 动态分区方式
set hive.exec.dynamic.partition=true;set hive.exec.dynamic.partition.mode=nonstrict;
insert overwrite table ods.ods_login_log partition(dt=2019070914) select * from ods.ods_login_log where dt=2019070914
```

- shell脚本实现

```shell
#/bin/bash
table=$1
echo $table
for p in $(hive -e "show partitions ods.$table;")
do
        echo $p
        echo "-------"
        hive -e "set hive.exec.dynamic.partition=true;set hive.exec.dynamic.partition.mode=nonstrict;insert overwrite table ods.$table partition(dt) select * from ods.$table where $p"
done

```

	相当于提前跑MR读取文件进行合并

- 缺点
	每批次跑一次过于频繁，影响实时批处理程序

### 2.2 重分区方式
- 实现说明
创建的DataFrame的时候,cache一下,然后对DataFrame进行重新分区,可以把分区设置为1,可以用reparation,当然也可以用coalesce
- 缺点
降低了写入的性能,所以数据量不是特别大的时候,还是可以用的,但是如果数据量很大,就需谨慎使用

### 2.3 第三方程序

> 本人未试过，借鉴网上大神的实现 -.-

- 实现说明
Hadoop的FileUtil工具类中提供了copyMerge()方法，它专门用来将一个HDFS目录下的所有文件合并成一个文件并输出，其源码如下：
 ```java
public static boolean copyMerge(FileSystem srcFS, Path srcDir, 
                                  FileSystem dstFS, Path dstFile, 
                                  boolean deleteSource,
                                  Configuration conf, String addString) throws IOException {
    dstFile = checkDest(srcDir.getName(), dstFS, dstFile, false);

    if (!srcFS.getFileStatus(srcDir).isDirectory())
      return false;
   
    OutputStream out = dstFS.create(dstFile);
    
    try {
      FileStatus contents[] = srcFS.listStatus(srcDir);
      Arrays.sort(contents);
      for (int i = 0; i < contents.length; i++) {
        if (contents[i].isFile()) {
          InputStream in = srcFS.open(contents[i].getPath());
          try {
            IOUtils.copyBytes(in, out, conf, false);
            if (addString!=null)
              out.write(addString.getBytes("UTF-8"));
                
          } finally {
            in.close();
          } 
        }
      }
    } finally {
      out.close();
    }
    
    if (deleteSource) {
      return srcFS.delete(srcDir, true);
    } else {
      return true;
    }
  }
 ```

可以写一个简单的程序，通过调用copyMerge()方法合并Hive外部表对应分区的文件，并且按照分区的时间粒度（天、小时等）调度。源数据的文件夹可以通过参数来指定，并且设置deleteSource参数为true，就能在合并完成后删除原来的小文件。需要注意的是，为了避免将当前正在写入的文件也合并进去，调度需要有一点延时

- 缺点
为了避免将当前正在写入的文件也合并进去，调度需要有一点延时